{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-14T03:12:42.790323Z",
     "start_time": "2024-12-14T03:12:02.323494Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import t, norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Constants\n",
    "num_train = 5_000  # Number of training samples\n",
    "num_test = 50_000  # Number of test samples\n",
    "r = np.array([.295, .49, .41, .415, .338, .64, .403, .476])\n",
    "sector_indices = data['sector'].values\n",
    "sec_loading = r[sector_indices]\n",
    "datat = norm.ppf(data['p'])\n",
    "\n",
    "# Function to compute loss for a single observation\n",
    "def compute_loss(obs):\n",
    "    m_factor = obs[0]\n",
    "    sec_factor = obs[:len(r)][sector_indices]\n",
    "    res_factor = obs[len(r):]\n",
    "\n",
    "    control_variate = (\n",
    "            r[0]**0.5 * m_factor\n",
    "            + (sec_loading - r[0])**0.5 * sec_factor\n",
    "            + (1 - sec_loading)**0.5 * res_factor\n",
    "    )\n",
    "    ind = control_variate < datat\n",
    "    loss = np.zeros(len(data))\n",
    "\n",
    "    if np.any(ind):\n",
    "        loss[ind] = (\n",
    "                data.loc[ind, 'm'].values\n",
    "                + data.loc[ind, 'd'].values\n",
    "                * np.clip(t.rvs(df=3, size=sum(ind)), -5, 5)\n",
    "        )\n",
    "    return np.sum(loss)\n",
    "\n",
    "# Generate Training Data for GPR\n",
    "print(\"Generating training data for GPR surrogate model...\")\n",
    "train_factors = np.random.normal(0, 1, (num_train, len(r) + len(data)))\n",
    "train_losses = Parallel(n_jobs=-1)(delayed(compute_loss)(obs) for obs in train_factors)\n",
    "train_factors = train_factors[:, :len(r)]  # Use factors only as inputs\n",
    "\n",
    "# Train GPR Model\n",
    "print(\"Training Gaussian Process Regression model...\")\n",
    "kernel = C(1.0, (1e-2, 1e2)) * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)\n",
    "gpr.fit(train_factors, train_losses)\n",
    "\n",
    "# Predict Losses on Test Data\n",
    "print(\"Predicting losses with GPR surrogate model...\")\n",
    "test_factors = np.random.normal(0, 1, (num_test, len(r)))\n",
    "predicted_losses, sigma = gpr.predict(test_factors, return_std=True)\n",
    "\n",
    "# Compute VaR and Variance for GPR\n",
    "VaR_gpr = np.percentile(-predicted_losses, 99.9)\n",
    "gpr_variance = np.var(predicted_losses)\n",
    "\n",
    "print(f\"GPR Surrogate Model VaR (99.9%): {VaR_gpr:.2f}\")\n",
    "print(f\"GPR Surrogate Model Variance: {gpr_variance:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
