{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, scipy.stats as st\n",
    "from scipy.stats import t, norm\n",
    "from joblib import Parallel, delayed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "num_obvs = 100_000\n",
    "r = np.array([.295, .49, .41, .415, .338, .64, .403, .476])\n",
    "sector_indices = data['sector'].values\n",
    "sec_loading = r[sector_indices]\n",
    "datat = norm.ppf(data['p'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "948f3a1e37570d3d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def process_obs(obs):\n",
    "    m_factor = obs[0]\n",
    "    sec_factor = obs[:len(r)][sector_indices]\n",
    "    res_factor = obs[len(r):]\n",
    "\n",
    "    control_variate = (\n",
    "            r[0]**0.5 * m_factor\n",
    "            + (sec_loading - r[0])**0.5 * sec_factor\n",
    "            + (1 - sec_loading)**0.5 * res_factor\n",
    "    )\n",
    "\n",
    "    ind = control_variate < datat\n",
    "    loss = np.zeros(len(data))\n",
    "\n",
    "    if np.any(ind):\n",
    "        loss[ind] = data.loc[ind, 'm'].values + data.loc[ind, 'd'].values * np.clip(t.rvs(df=3, size=sum(ind)), -5, 5)\n",
    "\n",
    "    return np.sum(loss), np.var(loss)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e946eb6a3b56de68"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.stats import genpareto\n",
    "\n",
    "factors = np.random.normal(0, 1, (num_obvs, len(r) + len(data)))\n",
    "antithetic_factors = -factors\n",
    "combined_factors = np.vstack([factors, antithetic_factors])\n",
    "\n",
    "answers = Parallel(n_jobs=-1, verbose=5)(delayed(process_obs)(obs) for obs in combined_factors)\n",
    "answers = np.array(answers)\n",
    "\n",
    "sample_losses = answers[:, 0]\n",
    "sample_vars = answers[:, 1]\n",
    "\n",
    "threshold = np.percentile(sample_losses, 99)  # Top 1% of losses\n",
    "print(f\"Threshold for GPD: {threshold}\")\n",
    "\n",
    "excess_losses = sample_losses[sample_losses > threshold] - threshold\n",
    "\n",
    "shape, loc, scale = genpareto.fit(excess_losses)\n",
    "\n",
    "p_tail = 0.999  # Target quantile for VaR\n",
    "n_excess = len(excess_losses)\n",
    "VaR_parametric = threshold + scale / shape * ((num_obvs / n_excess * (1 - p_tail)) ** (-shape) - 1)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-12-14T03:01:02.129379Z"
    }
   },
   "id": "f0dc641580927572"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
